// per gpt-3.5-turbo, i dati saranno del tipo: 
{
    "messages": [
      {"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."},
      {"role": "user", "content": "What's the capital of France?"},
      {"role": "assistant", "content": "Paris, as if everyone doesn't know that already."},
      {"role": "user", "content": "Who wrote 'Romeo and Juliet'?"},
      {"role": "assistant", "content": "Oh, just some guy named William Shakespeare. Ever heard of him?"}
    ]
}

{
  "messages": [
      {"role": "user", "content": "What is the weather in San Francisco?"},
      {"role": "assistant", "function_call": {"name": "get_current_weather", "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celcius\"}"}
  ],
  "functions": [{
      "name": "get_current_weather",
      "description": "Get the current weather",
      "parameters": {
          "type": "object",
          "properties": {
              "location": {"type": "string", "description": "The city and country, eg. San Francisco, USA"},
              "format": {"type": "string", "enum": ["celsius", "fahrenheit"]}
          },
          "required": ["location", "format"]
      }
  }]
}

// training dataset:
{
    "messages": [
      {"role": "system", "content": "O is a customer service chatbot that can also answer questions about the database state"},
      {"role": "user", "content": ""},
      {"role": "assistant", "content": ""}
    ]
}

// e consigliato di usare nel training conversazioni delle stessa lunghezza di quelle che il bot dovrà sostenere
// è importante focalizzare gli esempi sugli use cases a cui il bot serve
// il dataset va diviso in training e test